{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Eco-Bot\n",
    "\n",
    "Eco-Bot is an initiative to combine the power of artificial intelligence with environmental awareness. As we face increasing challenges related to climate change and sustainability, Eco-Bot stands as a digital companion to guide users in making eco-friendly decisions. By harnessing the capabilities of OpenAI and the Autogen framework, Eco-Bot offers dynamic interactions to educate, inform, and inspire users towards sustainable practices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai diskcache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will test out the creation of eco-bot and and recycle racoon adding the characters to a chat with each other about how the requirements for an AI recycling Centre  the gma and the understanding agent with its 3 sub agents what how why be also in the chat helping to gather the information together \n",
    "\n",
    "## Eco-Bot Multi-Agent Chat for GBTS Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import autogen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat import UserProxyAgent, assistant_agent, Agent, ConversableAgent, GroupChat, GroupChatManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import autogen\n",
    "\n",
    "# Load open ai api key from .env file in eco_buddies folder in the root directory\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ORGANIZATION_ID = os.getenv(\"ORGANIZATION_ID\")\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4-1106-preview',\n",
    "        'api_key':'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',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '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',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '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',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k-0314',\n",
    "        'api_key': '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',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration for the agents\n",
    "gpt4_config = {\n",
    "    \"seed\": 42,  # change the seed for different trials\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": config_list,  # This should be defined as per your API keys and model preferences\n",
    "    \"timeout\": 120,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Multi-Agent Chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eco-Bot: Hello\n"
     ]
    }
   ],
   "source": [
    "class Eco_Bot:\n",
    "    def __init__(self):\n",
    "        self.understanding_agent = UnderstandingAgent(name=\"Understanding Agent\")\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        response = self.understanding_agent.handle_message(message)\n",
    "        return response\n",
    "\n",
    "    def initiate_chat(self, message):\n",
    "        print(f\"Eco-Bot: {message}\")\n",
    "        while True:\n",
    "            user_input = input(\"User: \")\n",
    "            if user_input.lower() in [\"exit\", \"quit\", \"terminate\"]:\n",
    "                print(\"Eco-Bot: Goodbye!\")\n",
    "                break\n",
    "            response = self.handle_message(user_input)\n",
    "            print(f\"Eco-Bot: {response}\")\n",
    "\n",
    "class UnderstandingAgent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.what_agent = WhatAgent(name=\"What Agent\")\n",
    "        self.how_agent = HowAgent(name=\"How Agent\")\n",
    "        self.why_agent = WhyAgent(name=\"Why Agent\")\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        if \"what\" in message.lower():\n",
    "            return self.what_agent.handle_message(message)\n",
    "        elif \"how\" in message.lower():\n",
    "            return self.how_agent.handle_message(message)\n",
    "        elif \"why\" in message.lower():\n",
    "            return self.why_agent.handle_message(message)\n",
    "        else:\n",
    "            return f\"{self.name} does not understand the message: {message}\"\n",
    "class WhatAgent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        return f\"{self.name} is handling 'What' query: {message}\"\n",
    "\n",
    "class HowAgent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        return f\"{self.name} is handling 'How' query: {message}\"\n",
    "\n",
    "class WhyAgent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        return f\"{self.name} is handling 'Why' query: {message}\"\n",
    "    \n",
    "# Example of how to use the Eco_Bot class\n",
    "eco_bot = Eco_Bot()\n",
    "eco_bot.initiate_chat(\"Hello\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Proxy Agent Initialization\n",
    "\n",
    "This script initializes a User Proxy Agent for a chat system. Here's a breakdown of the parameters:\n",
    "\n",
    "- `name`: The name of the agent, in this case, \"User_proxy\".\n",
    "- `system_message`: A message that the system uses, in this case, \"A human admin.\"\n",
    "- `code_execution_config`: A dictionary that contains configuration for code execution. It specifies the last number of messages to consider and the working directory.\n",
    "- `human_input_mode`: The mode for human input. In this case, it's set to \"TERMINATE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UnderstandingAgent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.what_agent = WhatAgent(name=\"What Agent\")\n",
    "        self.how_agent = HowAgent(name=\"How Agent\")\n",
    "        self.why_agent = WhyAgent(name=\"Why Agent\")\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        if \"what\" in message.lower():\n",
    "            return self.what_agent.handle_message(message)\n",
    "        elif \"how\" in message.lower():\n",
    "            return self.how_agent.handle_message(message)\n",
    "        elif \"why\" in message.lower():\n",
    "            return self.why_agent.handle_message(message)\n",
    "        else:\n",
    "            return f\"{self.name} does not understand the message: {message}\"\n",
    "class WhatAgent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        return f\"{self.name} is handling 'What' query: {message}\"\n",
    "\n",
    "class HowAgent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        return f\"{self.name} is handling 'How' query: {message}\"\n",
    "\n",
    "class WhyAgent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        return f\"{self.name} is handling 'Why' query: {message}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralManager:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.task_master = TaskMaster(name=\"Task Master\")\n",
    "        self.main_safety_agent = SafetyAgent(name=\"Main Safety Agent\")\n",
    "        self.error_handling_safety_agent = SafetyAgent(name=\"Error Handling Safety Agent\")\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        response = self.task_master.handle_message(message)\n",
    "        if \"error\" in response.lower():\n",
    "            error_response = self.error_handling_safety_agent.handle_message(response)\n",
    "            return error_response\n",
    "        return response\n",
    "\n",
    "    def monitor_safety(self, script):\n",
    "        if \"unsafe\" in script:\n",
    "            alert = self.main_safety_agent.handle_message(\"Safety breach detected!\")\n",
    "            return alert\n",
    "        return \"Script is safe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskMaster:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        return f\"{self.name} received a task: {message}\"\n",
    "\n",
    "class SafetyAgent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        return f\"{self.name} alert: {message}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskMaker:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def formulate_task(self, message):\n",
    "        task = f\"Formulated Task based on: {message}\"\n",
    "        return task\n",
    "\n",
    "class TaskDelegator:\n",
    "    def __init__(self, name, worker_agents):\n",
    "        self.name = name\n",
    "        self.worker_agents = worker_agents\n",
    "\n",
    "    def delegate_task(self, task):\n",
    "        worker_agent = self.worker_agents.pop(0)\n",
    "        self.worker_agents.append(worker_agent)\n",
    "        response = worker_agent.handle_message(task)\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkerAgent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def handle_message(self, message):\n",
    "        return f\"{self.name} is processing the task: {message}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "Let's start the group chat. discuss the following topic: \"How to reduce carbon footprint?\"\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "please install openai and diskcache to use the autogen.oai subpackage.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\notebooks\\Autogen_Eco_group_chat.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m manager \u001b[39m=\u001b[39m GroupChatManager(groupchat\u001b[39m=\u001b[39mgroupchat, llm_config\u001b[39m=\u001b[39mllm_config)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# This code assumes that the autogen library is properly installed and configured,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# and that the API keys and other configurations are correctly set.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     manager,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mLet\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms start the group chat. discuss the following topic: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHow to reduce carbon footprint?\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:127\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39m# select the next speaker\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39;49mselect_speaker(speaker, \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    128\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39mgenerate_reply(sender\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:56\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[1;34m(self, last_speaker, selector)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m n_agents \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m     52\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGroupChat is underpopulated with \u001b[39m\u001b[39m{\u001b[39;00mn_agents\u001b[39m}\u001b[39;00m\u001b[39m agents. Direct communication would be more efficient.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[1;32m---> 56\u001b[0m final, name \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mgenerate_oai_reply(\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessages\n\u001b[0;32m     58\u001b[0m     \u001b[39m+\u001b[39;49m [\n\u001b[0;32m     59\u001b[0m         {\n\u001b[0;32m     60\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     61\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRead the above conversation. Then select the next role from \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent_names\u001b[39m}\u001b[39;49;00m\u001b[39m to play. Only return the role.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     62\u001b[0m         }\n\u001b[0;32m     63\u001b[0m     ]\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m final:\n\u001b[0;32m     66\u001b[0m     \u001b[39m# i = self._random.randint(0, len(self._agent_names) - 1)  # randomly pick an id\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_agent(last_speaker)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    603\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m    605\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m    607\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mllm_config\n\u001b[0;32m    608\u001b[0m )\n\u001b[0;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\oai\\completion.py:780\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make a completion for a given context.\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \n\u001b[0;32m    714\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39m        - `pass_filter`: whether the response passes the filter function. None if no filter is provided.\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[39mif\u001b[39;00m ERROR:\n\u001b[1;32m--> 780\u001b[0m     \u001b[39mraise\u001b[39;00m ERROR\n\u001b[0;32m    782\u001b[0m \u001b[39m# Warn if a config list was provided but was empty\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(config_list) \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(config_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\notebooks\\Autogen_Eco_group_chat.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m manager \u001b[39m=\u001b[39m GroupChatManager(groupchat\u001b[39m=\u001b[39mgroupchat, llm_config\u001b[39m=\u001b[39mllm_config)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# This code assumes that the autogen library is properly installed and configured,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# and that the API keys and other configurations are correctly set.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     manager,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mLet\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms start the group chat. discuss the following topic: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHow to reduce carbon footprint?\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:127\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39m# select the next speaker\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39;49mselect_speaker(speaker, \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    128\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39mgenerate_reply(sender\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:56\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[1;34m(self, last_speaker, selector)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m n_agents \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m     52\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGroupChat is underpopulated with \u001b[39m\u001b[39m{\u001b[39;00mn_agents\u001b[39m}\u001b[39;00m\u001b[39m agents. Direct communication would be more efficient.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[1;32m---> 56\u001b[0m final, name \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mgenerate_oai_reply(\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessages\n\u001b[0;32m     58\u001b[0m     \u001b[39m+\u001b[39;49m [\n\u001b[0;32m     59\u001b[0m         {\n\u001b[0;32m     60\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     61\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRead the above conversation. Then select the next role from \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent_names\u001b[39m}\u001b[39;49;00m\u001b[39m to play. Only return the role.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     62\u001b[0m         }\n\u001b[0;32m     63\u001b[0m     ]\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m final:\n\u001b[0;32m     66\u001b[0m     \u001b[39m# i = self._random.randint(0, len(self._agent_names) - 1)  # randomly pick an id\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_agent(last_speaker)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    603\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m    605\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m    607\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mllm_config\n\u001b[0;32m    608\u001b[0m )\n\u001b[0;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\oai\\completion.py:780\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make a completion for a given context.\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \n\u001b[0;32m    714\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39m        - `pass_filter`: whether the response passes the filter function. None if no filter is provided.\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[39mif\u001b[39;00m ERROR:\n\u001b[1;32m--> 780\u001b[0m     \u001b[39mraise\u001b[39;00m ERROR\n\u001b[0;32m    782\u001b[0m \u001b[39m# Warn if a config list was provided but was empty\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(config_list) \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(config_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\notebooks\\Autogen_Eco_group_chat.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m manager \u001b[39m=\u001b[39m GroupChatManager(groupchat\u001b[39m=\u001b[39mgroupchat, llm_config\u001b[39m=\u001b[39mllm_config)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# This code assumes that the autogen library is properly installed and configured,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# and that the API keys and other configurations are correctly set.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     manager,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mLet\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms start the group chat. discuss the following topic: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHow to reduce carbon footprint?\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:127\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39m# select the next speaker\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39;49mselect_speaker(speaker, \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    128\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39mgenerate_reply(sender\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:56\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[1;34m(self, last_speaker, selector)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m n_agents \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m     52\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGroupChat is underpopulated with \u001b[39m\u001b[39m{\u001b[39;00mn_agents\u001b[39m}\u001b[39;00m\u001b[39m agents. Direct communication would be more efficient.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[1;32m---> 56\u001b[0m final, name \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mgenerate_oai_reply(\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessages\n\u001b[0;32m     58\u001b[0m     \u001b[39m+\u001b[39;49m [\n\u001b[0;32m     59\u001b[0m         {\n\u001b[0;32m     60\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     61\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRead the above conversation. Then select the next role from \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent_names\u001b[39m}\u001b[39;49;00m\u001b[39m to play. Only return the role.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     62\u001b[0m         }\n\u001b[0;32m     63\u001b[0m     ]\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m final:\n\u001b[0;32m     66\u001b[0m     \u001b[39m# i = self._random.randint(0, len(self._agent_names) - 1)  # randomly pick an id\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_agent(last_speaker)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    603\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m    605\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m    607\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mllm_config\n\u001b[0;32m    608\u001b[0m )\n\u001b[0;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\oai\\completion.py:780\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make a completion for a given context.\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \n\u001b[0;32m    714\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39m        - `pass_filter`: whether the response passes the filter function. None if no filter is provided.\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[39mif\u001b[39;00m ERROR:\n\u001b[1;32m--> 780\u001b[0m     \u001b[39mraise\u001b[39;00m ERROR\n\u001b[0;32m    782\u001b[0m \u001b[39m# Warn if a config list was provided but was empty\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(config_list) \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(config_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\notebooks\\Autogen_Eco_group_chat.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m manager \u001b[39m=\u001b[39m GroupChatManager(groupchat\u001b[39m=\u001b[39mgroupchat, llm_config\u001b[39m=\u001b[39mllm_config)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# This code assumes that the autogen library is properly installed and configured,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# and that the API keys and other configurations are correctly set.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     manager,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mLet\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms start the group chat. discuss the following topic: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHow to reduce carbon footprint?\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:127\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39m# select the next speaker\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39;49mselect_speaker(speaker, \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    128\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39mgenerate_reply(sender\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:56\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[1;34m(self, last_speaker, selector)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m n_agents \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m     52\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGroupChat is underpopulated with \u001b[39m\u001b[39m{\u001b[39;00mn_agents\u001b[39m}\u001b[39;00m\u001b[39m agents. Direct communication would be more efficient.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[1;32m---> 56\u001b[0m final, name \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mgenerate_oai_reply(\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessages\n\u001b[0;32m     58\u001b[0m     \u001b[39m+\u001b[39;49m [\n\u001b[0;32m     59\u001b[0m         {\n\u001b[0;32m     60\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     61\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRead the above conversation. Then select the next role from \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent_names\u001b[39m}\u001b[39;49;00m\u001b[39m to play. Only return the role.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     62\u001b[0m         }\n\u001b[0;32m     63\u001b[0m     ]\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m final:\n\u001b[0;32m     66\u001b[0m     \u001b[39m# i = self._random.randint(0, len(self._agent_names) - 1)  # randomly pick an id\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_agent(last_speaker)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    603\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m    605\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m    607\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mllm_config\n\u001b[0;32m    608\u001b[0m )\n\u001b[0;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\oai\\completion.py:780\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make a completion for a given context.\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \n\u001b[0;32m    714\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39m        - `pass_filter`: whether the response passes the filter function. None if no filter is provided.\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[39mif\u001b[39;00m ERROR:\n\u001b[1;32m--> 780\u001b[0m     \u001b[39mraise\u001b[39;00m ERROR\n\u001b[0;32m    782\u001b[0m \u001b[39m# Warn if a config list was provided but was empty\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(config_list) \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(config_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\notebooks\\Autogen_Eco_group_chat.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     manager,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mLet\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms start the group chat. discuss the following topic: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHow to reduce carbon footprint?\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:127\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39m# select the next speaker\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39;49mselect_speaker(speaker, \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    128\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39mgenerate_reply(sender\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:56\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[1;34m(self, last_speaker, selector)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m n_agents \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m     52\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGroupChat is underpopulated with \u001b[39m\u001b[39m{\u001b[39;00mn_agents\u001b[39m}\u001b[39;00m\u001b[39m agents. Direct communication would be more efficient.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[1;32m---> 56\u001b[0m final, name \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mgenerate_oai_reply(\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessages\n\u001b[0;32m     58\u001b[0m     \u001b[39m+\u001b[39;49m [\n\u001b[0;32m     59\u001b[0m         {\n\u001b[0;32m     60\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     61\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRead the above conversation. Then select the next role from \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent_names\u001b[39m}\u001b[39;49;00m\u001b[39m to play. Only return the role.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     62\u001b[0m         }\n\u001b[0;32m     63\u001b[0m     ]\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m final:\n\u001b[0;32m     66\u001b[0m     \u001b[39m# i = self._random.randint(0, len(self._agent_names) - 1)  # randomly pick an id\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_agent(last_speaker)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    603\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m    605\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m    607\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mllm_config\n\u001b[0;32m    608\u001b[0m )\n\u001b[0;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\oai\\completion.py:780\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make a completion for a given context.\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \n\u001b[0;32m    714\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39m        - `pass_filter`: whether the response passes the filter function. None if no filter is provided.\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[39mif\u001b[39;00m ERROR:\n\u001b[1;32m--> 780\u001b[0m     \u001b[39mraise\u001b[39;00m ERROR\n\u001b[0;32m    782\u001b[0m \u001b[39m# Warn if a config list was provided but was empty\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(config_list) \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(config_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\notebooks\\Autogen_Eco_group_chat.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     manager,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mLet\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms start the group chat. discuss the following topic: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHow to reduce carbon footprint?\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:127\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39m# select the next speaker\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39;49mselect_speaker(speaker, \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    128\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39mgenerate_reply(sender\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:56\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[1;34m(self, last_speaker, selector)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m n_agents \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m     52\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGroupChat is underpopulated with \u001b[39m\u001b[39m{\u001b[39;00mn_agents\u001b[39m}\u001b[39;00m\u001b[39m agents. Direct communication would be more efficient.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[1;32m---> 56\u001b[0m final, name \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mgenerate_oai_reply(\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessages\n\u001b[0;32m     58\u001b[0m     \u001b[39m+\u001b[39;49m [\n\u001b[0;32m     59\u001b[0m         {\n\u001b[0;32m     60\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     61\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRead the above conversation. Then select the next role from \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent_names\u001b[39m}\u001b[39;49;00m\u001b[39m to play. Only return the role.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     62\u001b[0m         }\n\u001b[0;32m     63\u001b[0m     ]\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m final:\n\u001b[0;32m     66\u001b[0m     \u001b[39m# i = self._random.randint(0, len(self._agent_names) - 1)  # randomly pick an id\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_agent(last_speaker)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    603\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m    605\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m    607\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mllm_config\n\u001b[0;32m    608\u001b[0m )\n\u001b[0;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\oai\\completion.py:780\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make a completion for a given context.\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \n\u001b[0;32m    714\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39m        - `pass_filter`: whether the response passes the filter function. None if no filter is provided.\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[39mif\u001b[39;00m ERROR:\n\u001b[1;32m--> 780\u001b[0m     \u001b[39mraise\u001b[39;00m ERROR\n\u001b[0;32m    782\u001b[0m \u001b[39m# Warn if a config list was provided but was empty\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(config_list) \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(config_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\notebooks\\Autogen_Eco_group_chat.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     manager,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mLet\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms start the group chat. discuss the following topic: \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHow to reduce carbon footprint?\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/OneDrive/Desktop/Buisness/KHM%20Smart%20Build/Coding/Projects/OCFS_projects/Eco-Bot/notebooks/Autogen_Eco_group_chat.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:127\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39m# select the next speaker\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39;49mselect_speaker(speaker, \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    128\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39mgenerate_reply(sender\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:56\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[1;34m(self, last_speaker, selector)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m n_agents \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m     52\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGroupChat is underpopulated with \u001b[39m\u001b[39m{\u001b[39;00mn_agents\u001b[39m}\u001b[39;00m\u001b[39m agents. Direct communication would be more efficient.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[1;32m---> 56\u001b[0m final, name \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mgenerate_oai_reply(\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessages\n\u001b[0;32m     58\u001b[0m     \u001b[39m+\u001b[39;49m [\n\u001b[0;32m     59\u001b[0m         {\n\u001b[0;32m     60\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     61\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRead the above conversation. Then select the next role from \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent_names\u001b[39m}\u001b[39;49;00m\u001b[39m to play. Only return the role.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     62\u001b[0m         }\n\u001b[0;32m     63\u001b[0m     ]\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m final:\n\u001b[0;32m     66\u001b[0m     \u001b[39m# i = self._random.randint(0, len(self._agent_names) - 1)  # randomly pick an id\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_agent(last_speaker)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    603\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m    605\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m    607\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mllm_config\n\u001b[0;32m    608\u001b[0m )\n\u001b[0;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\Buisness\\KHM Smart Build\\Coding\\Projects\\OCFS_projects\\Eco-Bot\\eco-bot_env\\Lib\\site-packages\\autogen\\oai\\completion.py:780\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make a completion for a given context.\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \n\u001b[0;32m    714\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39m        - `pass_filter`: whether the response passes the filter function. None if no filter is provided.\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[39mif\u001b[39;00m ERROR:\n\u001b[1;32m--> 780\u001b[0m     \u001b[39mraise\u001b[39;00m ERROR\n\u001b[0;32m    782\u001b[0m \u001b[39m# Warn if a config list was provided but was empty\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(config_list) \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(config_list) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mImportError\u001b[0m: please install openai and diskcache to use the autogen.oai subpackage."
     ]
    }
   ],
   "source": [
    "# Import the necessary classes from autogen\n",
    "import openai\n",
    "import diskcache\n",
    "from autogen.agentchat import UserProxyAgent, AssistantAgent, GroupChat, GroupChatManager\n",
    "\n",
    "# Define your actual llm_config with real API configuration\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,  # replace with your actual config_list with API keys\n",
    "    \"seed\": 42  # Optional: The seed can be set for reproducibility\n",
    "}\n",
    "\n",
    "# Initialize the agents\n",
    "Eco_Bot = UserProxyAgent(\n",
    "    name=\"Eco-Bot\",\n",
    "    system_message=\"Hello, I am Eco-Bot. I am here to help you with your queries.\",\n",
    "    code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n",
    "    human_input_mode=\"TERMINATE\"\n",
    ")\n",
    "coder = AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "pm = AssistantAgent(\n",
    "    name=\"General Manager\",\n",
    "    system_message=\"Hello, I am the General Manager. I will be managing the group chat.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "SafetyAgent = AssistantAgent(\n",
    "    name=\"Safety Agent\",\n",
    "    system_message=\"Hello, I am the Safety Agent. I will be monitoring the safety of the group chat.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "Agent = AssistantAgent(\n",
    "    name=\"Agent\",\n",
    "    system_message=\"Hello, I am the Agent. I will be handling the tasks.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Instantiate the GroupChat\n",
    "groupchat = GroupChat(agents=[Eco_Bot, coder, pm, SafetyAgent, Agent], messages=[], max_round=12)\n",
    "\n",
    "# Instantiate the GroupChatManager\n",
    "manager = GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "\n",
    "# This code assumes that the autogen library is properly installed and configured,\n",
    "# and that the API keys and other configurations are correctly set.\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"\"\"\n",
    "Let's start the group chat. discuss the following topic: \"How to reduce carbon footprint?\"\n",
    "\"\"\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eco-bot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
